{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "# read the data from disk and split into lines\n",
    "# we use .strip() to remove the final (empty) line\n",
    "with open(\"./data/yelp.json\") as f:\n",
    "    reviews = f.read().strip().split(\"\\n\")\n",
    "\n",
    "# each line of the file is a separate JSON object\n",
    "reviews = [json.loads(review) for review in reviews] \n",
    "\n",
    "# we're interested in the text of each review \n",
    "# and the stars rating, so we load these into \n",
    "# separate lists\n",
    "texts = [review['text'] for review in reviews]\n",
    "stars = [review['stars'] for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def balance_classes(xs, ys):\n",
    "    freqs = Counter(ys)\n",
    "\n",
    "    # the least common class is the maximum number we want for all classes\n",
    "    max_allowable = freqs.most_common()[-1][1]\n",
    "    num_added = {clss: 0 for clss in freqs.keys()}\n",
    "    new_ys = []\n",
    "    new_xs = []\n",
    "    for i, y in enumerate(ys):\n",
    "        if num_added[y] < max_allowable:\n",
    "            new_ys.append(y)\n",
    "            new_xs.append(xs[i])\n",
    "            num_added[y] += 1\n",
    "    return new_xs, new_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4: 79878, 5: 76193, 3: 35363, 2: 20957, 1: 17516})\n",
      "Counter({5: 17516, 4: 17516, 2: 17516, 3: 17516, 1: 17516})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(stars))\n",
    "balanced_x, balanced_y = balance_classes(texts, stars)\n",
    "print(Counter(balanced_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:51.731333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# This vectorizer breaks text into single words and bi-grams\n",
    "# and then calculates the TF-IDF representation\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "t1 = datetime.datetime.now()\n",
    "\n",
    "# the 'fit' builds up the vocabulary from all the reviews\n",
    "# while the 'transform' step turns each indivdual text into\n",
    "# a matrix of numbers.\n",
    "vectors = vectorizer.fit_transform(balanced_x)\n",
    "print(datetime.datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, balanced_y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:22.477658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# initialise the SVM classifier\n",
    "classifier = LinearSVC()\n",
    "\n",
    "# train the classifier\n",
    "t1 = datetime.datetime.now()\n",
    "classifier.fit(X_train, y_train)\n",
    "print(datetime.datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1, 1, 5, 4, 3, 2, 1, 4, 5, 2, 1, 1, 1, 5, 4, 4, 1, 4, 2]\n",
      "[3, 3, 2, 5, 3, 3, 2, 1, 4, 5, 2, 1, 1, 1, 5, 4, 5, 1, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "preds = classifier.predict(X_test)\n",
    "print(list(preds[:20]))\n",
    "print(y_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\n",
      "\n",
      "Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\n",
      "\n",
      "While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I've ever had.\n",
      "\n",
      "Anyway, I can't wait to go back!\n",
      "------\n",
      "General Manager Scott Petello is a good egg!!! Not to go into detail, but let me assure you if you have any issues (albeit rare) speak with Scott and treat the guy with some respect as you state your case and I'd be surprised if you don't walk out totally satisfied as I just did. Like I always say..... \"Mistakes are inevitable, it's how we recover from them that is important\"!!!\n",
      "\n",
      "Thanks to Scott and his awesome staff. You've got a customer for life!! .......... :^)\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "print('------')\n",
    "print(texts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classifier.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pickle\n",
    "# with open('yelp-classifier.pkl', 'wb') as picklefile:  \n",
    "#     pickle.dump(classifier,picklefile)\n",
    "\n",
    "# # Save tuple\n",
    "# tuple_objects = (classifier, X_train, y_train)\n",
    "# pickle.dump(tuple_objects, open(\"yelp-classifier-tuple.pkl\", 'wb'))\n",
    "\n",
    "#joblib save\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "joblib.dump(classifier, 'classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
